{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Exercise - Spam filter \n",
    "\n",
    "Table of contents \n",
    "    1. Load the data & import tools \n",
    "    2. Helper functions \n",
    "        Stratified Triple Cross Validation \n",
    "        Custom Scoring Function \n",
    "    3. Naive Bayes \n",
    "        Helper functions\n",
    "        'Manual' grid search \n",
    "        Plot results \n",
    "        Find best alpha\n",
    "            'manually'\n",
    "            w/ RandomizedSearchCV\n",
    "        Test it on the test set \n",
    "    4. SVM \n",
    "        Helper functions \n",
    "        Experiment 1 \n",
    "        Experiment 2 \n",
    "        Experiment 3 \n",
    "        Experiment 4 \n",
    "        Experiment 5\n",
    "        Precision / Recall curve of results\n",
    "    5. Random Forests \n",
    "        Helper functions \n",
    "        Experiment 1 \n",
    "        Experiment 2 \n",
    "        Experiment 3 \n",
    "        Experiment 4 \n",
    "        Experiment 5\n",
    "        Precision / Recall curve of results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "    The data has already been pre-processed to a bag of words representation, with a word count vector for each email.\n",
    "    Stored in a sparse matrix, with 10.000 emails (data rows) and 57173 words (features).\n",
    "    \n",
    "    The following cell gets the data into a variable we can work with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57173, 10000)\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from inspect import signature\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score \n",
    "\n",
    "\n",
    "def get_data(name ):\n",
    "    \"\"\"\n",
    "    :param name: name of .mat file in working directory\n",
    "    :return:\n",
    "        measurements are the bag of words representation of the emails\n",
    "        labels are the corresponding labels\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(name)\n",
    "    measurements = mat['X']\n",
    "    labels = mat['Y']\n",
    "    print(measurements.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    return measurements, labels[0]\n",
    "\n",
    "os.chdir(\"/Users/valdimareggertsson/Documents/Valdi/Sumarönn 2019/Machine Learning/Projects/\")\n",
    "\n",
    "m,l = get_data(\"emails.mat\")\n",
    "m_t = m.transpose()\n",
    "# m is 10000 x 57173,   emails by words sparse matrix\n",
    "    # data x features, meikar meira sense\n",
    "# l is 1 x 1000 ,  labels by email\n",
    "N = m.shape[1]\n",
    "# N is number of emails\n",
    "\n",
    "# m_t only has the counts. \n",
    "# Let's get a matrix with term frequencies weighted by inverse document frequency:\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True, norm='l2')\n",
    "tfidf_transformer.fit(m_t)\n",
    "tfidf_m_t = tfidf_transformer.transform(m_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Functions used\n",
    "    i) conf_interpretation, which gets precision/accuracy/FPR/TPR from confusion matrix\n",
    "    ii) cvkfold, which does k-fold stratified cross validation and splits the data set into train/validate/test\n",
    "    iii) train_avg_cv, which trains a model using k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_interpretation(con):\n",
    "    \"\"\"\n",
    "    con is the output of metrics.confusion_matrix()\n",
    "    \"\"\"\n",
    "    tp = con[1][1]\n",
    "    fn = con[1][0]\n",
    "    fp = con[0][1]\n",
    "    tn = con[0][0]\n",
    "    precision = tp / (tp+fp)\n",
    "    r_fp = fp / (fp+tn)\n",
    "    # false positive rate / false alarm rate\n",
    "    # which must be max 0.002\n",
    "    \n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp+tn+fn+fp)\n",
    "  \n",
    "    return precision, accuracy, r_fp, recall \n",
    "\n",
    "\n",
    "def cvkfold(data, l, k):\n",
    "    \"\"\"\n",
    "    data: matrix of measurements\n",
    "    l: vector of labels \n",
    "    k: number of splits \n",
    "    returns: \n",
    "        a list of length k X_train/X_validate cross-validation pairs \n",
    "        X_test, y_test - a reserved test set containing 1/k of the rows from 'data'\n",
    "        all stratified, i.e. with original class ratios\n",
    "    \"\"\"\n",
    "    kf = StratifiedKFold(n_splits = k)\n",
    "\n",
    "    i = 0 \n",
    "    for train_index, test_index in kf.split(data, l):\n",
    "\n",
    "        if i == 0:\n",
    "            # reserve for testing \n",
    "            X_test = data[test_index]\n",
    "            y_test = l[test_index]\n",
    "        # hvað er í gangi hérna\n",
    "        # ach ja, test tekið frá og restin notuð í train/validate \n",
    "            X = data[train_index]\n",
    "            y = l[train_index]\n",
    "\n",
    "\n",
    "    X_train, y_train = [], []\n",
    "    X_validate, y_validate = [],[] \n",
    "    # X og y eru hráefni fyrir train/validation split \n",
    "    for tr, te in kf.split(X,y):\n",
    "        X_train.append(data[tr])\n",
    "        y_train.append(l[tr])\n",
    "\n",
    "        X_validate.append(data[te])\n",
    "        y_validate.append(l[te])    \n",
    "\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "\n",
    "def train_avg_cv(model, data,k):\n",
    "    \"\"\"\n",
    "    Use: p, a = train_avg_cv(model,data)\n",
    "    Before:  \n",
    "        'model' is a classifier, \n",
    "        'data' is the matrix of measurements \n",
    "        'k' is the number of splits for CV \n",
    "    After: \n",
    "        p is the average precision found through k-fold cross validation\n",
    "        a is the average accuracy found through k-fold cross validation\n",
    "        cons is a list of confusion matrices for the splits \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = cvkfold(data,l,k)\n",
    "    avg_r_fp = 0 \n",
    "    avg_r_tp = 0 \n",
    "    avg_precision = 0 \n",
    "    avg_accuracy = 0 \n",
    "    cons = []\n",
    "    for i in range(k):\n",
    "        model.fit(X_train[i], y_train[i])\n",
    "        pred = model.predict(X_validate[i])\n",
    "        con = confusion_matrix(y_validate[i],pred)\n",
    "        avg_precision += 1/k*conf_interpretation(con)[0]\n",
    "        avg_accuracy += 1/k*conf_interpretation(con)[1]\n",
    "        avg_r_fp += 1/k*conf_interpretation(con)[2]\n",
    "        avg_r_tp += 1/k*conf_interpretation(con)[3]\n",
    "        cons.append(con)\n",
    "        print(con)\n",
    "\n",
    "    return avg_precision, avg_accuracy, avg_r_fp, avg_r_tp\n",
    "\n",
    "\n",
    "def show_best(random_results):\n",
    "    \"\"\" \n",
    "    random_results is the outcome of RandomizedSearchCV()\n",
    "    \"\"\"\n",
    "    best_prediction = random_results.best_estimator_.predict(X_test)\n",
    "    con = confusion_matrix(y_test, best_prediction)\n",
    "    print(conf_interpretation(con))\n",
    "    print(con)\n",
    "    print(random_results.best_estimator_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes\n",
    "\n",
    "The typical method for solving this task.\n",
    "\n",
    "Functions: \n",
    "    - param_range,  which makes a list of hyperparameters (alpha) to check \n",
    "    - good_NB_classifiers,  which filters out only those hyperparameters that fulfil certain criteria \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_range(start, end, rate):\n",
    "    \"\"\"\n",
    "    returns: range(start,end,dx) distributed unevenly\n",
    "    \"\"\"\n",
    "    parameters = []\n",
    "    a = start \n",
    "    while(a < end):\n",
    "        a += a/rate\n",
    "        parameters.append(a)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def good_NB_classifiers(params_to_check, min_precision, min_accuracy, min_rfp, data,k):\n",
    "    \"\"\"\n",
    "    Use: alphas_OK = good_NB_classifiers(params_to_check, min_precision)\n",
    "    Before: \n",
    "        params_to_check is a list of hyperparameter values for NB\n",
    "        min_precision, min_accuracy and min_rfp are requirements for precision/accuracy/false positive rate\n",
    "        data is the matrix of measurements \n",
    "    After: \n",
    "        alphas_OK is a list of (precision, accuracy, FP rate, TP rate, parameter value) after k-fold CV with NB\n",
    "    \"\"\"\n",
    "\n",
    "    params_OK = []\n",
    "    for param in params_to_check:\n",
    "        p,a,rfp,rtp = train_avg_cv(MultinomialNB(param), data,k)\n",
    "        if p > min_precision and a > min_accuracy and rfp < min_rfp :\n",
    "            params_OK.append((p,a, rfp, rtp, param))\n",
    "        # a has the max precision\n",
    "    return params_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a range of parameters and find adequate models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "min_precision = 0.999#0.999\n",
    "min_accuracy = 0.993\n",
    "max_rfp = 0.002\n",
    "\n",
    "params_to_check = param_range(5e-08,7e-05, 4) #[0.000001, 0.0001,0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0]      \n",
    "alphas_OK = good_NB_classifiers(params_to_check, min_precision, min_accuracy, max_rfp, m_t,20)\n",
    "print(\"Good enough, without IDF:\")\n",
    "print(alphas_OK)\n",
    "\n",
    "params_to_check = param_range(5e-8,1, 4) #[0.000001, 0.0001,0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0]      \n",
    "\n",
    "wide_range_NB = good_NB_classifiers(params_to_check, 0.95, 0.90, 0.01, m_t,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results that were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plotpics(results):\n",
    "    \"\"\"\n",
    "    Before: \n",
    "        results is output from good_NB_classifiers\n",
    "    After: \n",
    "        precision/recall, ROC and accuracy/precision/alpha curves have been displayed\n",
    "    \"\"\"\n",
    "    alphas = [x[4] for x in results]\n",
    "    precisions = [x[0] for x in results]\n",
    "    accuracies = [x[1] for x in results]\n",
    "\n",
    "    plt.plot(alphas,precisions, 'bo')\n",
    "    plt.plot(alphas, accuracies,'ro')\n",
    "    plt.legend([\"Precision\",\"Accuracy\"])\n",
    "    plt.xlabel(\"smoothing parameter alpha\")\n",
    "    plt.xticks([min(alphas), (min(alphas) + max(alphas))/2, max(alphas)])\n",
    "    plt.show()\n",
    "\n",
    "    fp_rate = [x[2] for x in results] \n",
    "    tp_rate = [x[3] for x in results]\n",
    "\n",
    "    ### Plot ROC\n",
    "    plt.plot(fp_rate, tp_rate)\n",
    "    plt.title(\"ROC\")\n",
    "    plt.xlim(0,0.003)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()\n",
    "\n",
    "    ### Plot Precision/Recall curve\n",
    "    plt.plot(tp_rate, precisions, \"bo\")\n",
    "    plt.xlim(0.95,1)\n",
    "    plt.ylim(0.9,1)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plotpics(alphas_OK_IDF)\n",
    "plotpics(wide_range_NB)\n",
    "\n",
    "# Tiny alphas:\n",
    "params_to_check = param_range(5e-4,1, 4)#[0.000001, 0.0001,0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0]      \n",
    "alphas_tiny = good_NB_classifiers(params_to_check, min_precision, min_accuracy, max_rfp, m_t,20)\n",
    "\n",
    "plotpics(alphas_tiny[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minFar_sortAcc(a_OK):\n",
    "    \n",
    "    alphas = [x[4] for x in a_OK]\n",
    "    precisions = [x[0] for x in a_OK]\n",
    "    accuracies = [x[1] for x in a_OK]   \n",
    "    fp_rate = [x[2] for x in a_OK] \n",
    "    tp_rate = [x[3] for x in a_OK]\n",
    "    \n",
    "    best = [x for x in a_OK if x[2] == np.max(fp_rate) and x[1] == np.max(accuracies)]\n",
    "\n",
    "    # Choose the highest alpha\n",
    "    best_alpha = np.max([x[4] for x in best])\n",
    "    \n",
    "    return best_alpha\n",
    "    \n",
    "    \n",
    "best_alpha = minFar_sortAcc(alphas_OK)\n",
    "            \n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best alpha found on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a training set with 80% of the data\n",
    "import scipy.sparse as sp\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = cvkfold(m_t,l,5)\n",
    "\n",
    "big_train_X = sp.csr_matrix(np.concatenate((X_validate[0].toarray(),X_train[0].toarray()),axis=0))\n",
    "big_train_y = np.concatenate((y_validate[0],y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb = MultinomialNB(best_alpha)\n",
    "\n",
    "best_nb.fit(big_train_X, big_train_y)\n",
    "prediction = best_nb.predict(X_test)\n",
    "con = confusion_matrix(y_test,prediction)\n",
    "\n",
    "print(con)\n",
    "\n",
    "print(metrics.classification_report(y_test,prediction))\n",
    "print(conf_interpretation(con))\n",
    "\n",
    "print(train_avg_cv(best_nb,m_t,59))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for alpha from sklearn with custom scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params_to_check = param_range(5e-8,7e-3, 4)\n",
    "random_grid = {'alpha': params_to_check}\n",
    "nb_random = RandomizedSearchCV(estimator = MultinomialNB(), param_distributions = random_grid, \n",
    "                                   scoring = scorer, n_iter = 10, cv = 5, random_state = 42, n_jobs = -1)\n",
    "nb_random.fit(big_train_X, big_train_y)\n",
    "show_best(nb_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC curve for NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = nb_random.best_estimator_\n",
    "\n",
    "model.fit(big_train_X, big_train_y)\n",
    "\n",
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ =roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example') \n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make precision-recall curve for NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "from sklearn.metrics import average_precision_score \n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "precision, recall, _ =precision_recall_curve(y_test, y_score)\n",
    "step_kwargs = ({'step': 'post'}\n",
    "if 'step' in signature(plt.fill_between).parameters\n",
    "else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and helper functions\n",
    "\n",
    "- Scale the data to variance 1 \n",
    "- train_avg_cv_fast(), function which does k-fold cross validation and stops if any of the splits have high FPR or low accuracy\n",
    "- good_SVM_classifiers(), function which filters out only models with good parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn wants the data scaled.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean = False)\n",
    "scaler.fit(m_t)\n",
    "m_t_s = scaler.transform(m_t)\n",
    "\n",
    "\n",
    "### To speed up the training. If the results of the first split give over 1% FPR, then stop training this model.\n",
    "def train_avg_cv_fast(model, data,k):\n",
    "    \"\"\"\n",
    "    Use: p, a = train_avg_cv(model,data)\n",
    "    Before:  \n",
    "        'model' is a classifier, \n",
    "        'data' is the matrix of measurements \n",
    "        'k' is the number of splits for CV \n",
    "    After: \n",
    "        p is the average precision found through k-fold cross validation\n",
    "        a is the average accuracy found through k-fold cross validation\n",
    "        cons is a list of confusion matrices for the splits \n",
    "        \n",
    "        Returns 0,0,0,0 if it seems hopeless \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = cvkfold(data,l,k)\n",
    "    avg_r_fp = 0 \n",
    "    avg_r_tp = 0 \n",
    "    avg_precision = 0 \n",
    "    avg_accuracy = 0 \n",
    "    cons = []\n",
    "    for i in range(k):\n",
    "        model.fit(X_train[i], y_train[i])\n",
    "        pred = model.predict(X_validate[i])\n",
    "        con = confusion_matrix(y_validate[i],pred)\n",
    "        \n",
    "        avg_precision += 1/k*conf_interpretation(con)[0]\n",
    "        avg_accuracy += 1/k*conf_interpretation(con)[1]\n",
    "        avg_r_fp += 1/k*conf_interpretation(con)[2]\n",
    "        avg_r_tp += 1/k*conf_interpretation(con)[3]\n",
    "        \n",
    "        if(conf_interpretation(con)[2] > 0.01  or conf_interpretation(con)[1] < 0.96):\n",
    "            print(\"Too many false positives or too low accuracy \")\n",
    "            return 0,0,0,0\n",
    "        \n",
    "        cons.append(con)\n",
    "        print(con)\n",
    "\n",
    "\n",
    "    return avg_precision, avg_accuracy, avg_r_fp, avg_r_tp\n",
    "\n",
    "def good_SVM_classifiers(kernel, weights,cs, data, max_fpr, min_acc):\n",
    "    \"\"\"\n",
    "    Use: \n",
    "        goodies =  good_SVM_classifiers(kernel, weights,cs, data)\n",
    "    Before: \n",
    "        kernel is a SVM kernel\n",
    "        weights is a list of weights for class_weight\n",
    "        cs is a list of paramters C \n",
    "        data is the dataset to be trained on \n",
    "        max_fpr is the maximum false positive rate which is good enough \n",
    "        min_acc is the minimum accuracy which is good enough \n",
    "    After: \n",
    "        goodies is the list of parameters/results that have are good enough\n",
    "    \"\"\"\n",
    "    good_cs = []\n",
    "    good_weights = []\n",
    "    good_results = []\n",
    "    results = []\n",
    "    for weight_dict in [{1:1, -1:x} for x in weights]:\n",
    "    \n",
    "        for c in cs:\n",
    "            results.append(train_avg_cv_fast(SVC(C = c, kernel = kernel, class_weight = weight_dict, max_iter = 1000), data,5))\n",
    "            if results[-1][2] < max_fpr  and results[-1][1] > min_acc:\n",
    "                # vista bara það sem er með <0.2% FPR \n",
    "                print(\"woohoo\")\n",
    "                print(\"weight:\")\n",
    "                print(weight_dict[-1])\n",
    "                print(\"C:\")\n",
    "                print(c)\n",
    "                good_cs.append(c)\n",
    "                good_weights.append(weight_dict[-1])\n",
    "                good_results.append(results[-1])\n",
    "            \n",
    "    return (kernel, good_weights, good_cs, good_results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "Try out different kernels and some C and class_weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "all_good = {}\n",
    "\n",
    "max_fpr = 0.002\n",
    "min_acc = 0.975\n",
    "\n",
    "cs = [0.5,1.5,5]\n",
    "weights = [3,5,7,10,100]\n",
    "\n",
    "for kernel in ['linear', 'rbf', 'sigmoid', 'poly']:\n",
    "    t0 = time()\n",
    "\n",
    "    all_good[kernel] = good_SVM_classifiers(kernel, weights, cies, m_t_s, max_fpr, min_acc)\n",
    "    print(\" done in %0.3fs\" % (time() - t0)) \n",
    "\n",
    "# all_good is a dict with the good classifiers for the 4 kernels and the weights tested "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "Search further around the models that were good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the good results that were found on the test set\n",
    "\n",
    "##### SVM parameters that look good,\n",
    "    Sigmoid: \n",
    "    weight -1 =  (5,7)\n",
    "    with C = 0.5 \n",
    "\n",
    "Let's try out values around those values.  Search with 10.000 iterations even?\n",
    "\n",
    "cs =  [0.4,... , 0.7] with 0.05 in between\n",
    "weights = [4... 9] með 0.5 in between \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.5\n",
    "for weight_dict in  [{1:1, -1:5}, {1:1, -1:7}]:\n",
    "    model = SVC(C = c, kernel = 'sigmoid', class_weight = weight_dict, max_iter = 1000)\n",
    "    model.fit(big_train_X, big_train_y)\n",
    "    prediction = model.predict(X_test)\n",
    "    con = confusion_matrix(y_test,prediction)\n",
    "\n",
    "    print(con)\n",
    "    print(metrics.classification_report(y_test,prediction))\n",
    "    print(conf_interpretation(con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turns out the nice results didn't generalise to the test set!\n",
    "\n",
    "Let's anyway search around them for something better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = param_range(0.3,2,15)\n",
    "weights = param_range(4,9,7)\n",
    "goodies = good_SVM_classifiers('sigmoid', weights, cs, m_t_s, max_fpr, min_acc)\n",
    "\n",
    "print(goodies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found a few good results:\n",
    "\n",
    "\n",
    "- weights_found = [4.571, 5.224, 5.970, 5.970, 6.824, 6.824]\n",
    "- c_found = [0.536, 0.503,0.536, 0.503, 0.536, 0.503, 0.536]\n",
    "\n",
    "How good is the best one? Let's try'em out on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_found = [4.571, 5.224, 5.970, 5.970, 6.824, 6.824]\n",
    "c_found = [0.536, 0.503,0.536, 0.503, 0.536, 0.503, 0.536]\n",
    "\n",
    "round2_goodvals = []\n",
    "good_mdls = []\n",
    "for i,w in enumerate(weights_found):\n",
    "    print(i)\n",
    "    modl = SVC(C = c_found[i], kernel = \"sigmoid\", class_weight = {1:1,-1:w}, max_iter = 1000)\n",
    "    round2_goodvals.append(train_avg_cv(modl, m_t_s,5))\n",
    "    good_mdls.append(modl)\n",
    "    \n",
    "# Test good models on test set:\n",
    "for model in good_mdls:\n",
    "    model.fit(big_train_X, big_train_y)\n",
    "    prediction = model.predict(X_test)\n",
    "    con = confusion_matrix(y_test,prediction)\n",
    "\n",
    "    print(str(i) + \"\\n\")\n",
    "    print(con)\n",
    "\n",
    "    print(metrics.classification_report(y_test,prediction))\n",
    "    print(conf_interpretation(con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "Search a wider range of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dc = 0.2\n",
    "staerd = dc\n",
    "cies = []\n",
    "for i in range(10):\n",
    "\n",
    "    cies.append(staerd)\n",
    "    if i % 9 == 0 and i >0:\n",
    "        #print(cies)\n",
    "        dc*=10\n",
    "    staerd = staerd+dc\n",
    "weights = [1,3,5,7,9,10,15,20,25,30,40,60,80,100]\n",
    "\n",
    "# cies is a list of values of C     \n",
    "# weights is a list for class_weights\n",
    "\n",
    "all_good3 = {}\n",
    "\n",
    "for kernel in ['linear', 'rbf', 'sigmoid', 'poly']:\n",
    "    t0 = time()\n",
    "\n",
    "    all_good3[kernel] = good_SVM_classifiers(kernel, weights, cies, m_t_s, max_fpr, min_acc)\n",
    "    print(\" done in %0.3fs\" % (time() - t0)) \n",
    "## all_good3 is a dict with the good classifiers for the 4 kernels and the weights tested "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_good3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "Bigger search, also for gamma.\n",
    "Try to have the data both scaled and not scaled.\n",
    "Keep te weights that have proved successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "gammas =['auto']\n",
    "for i in range(10):        \n",
    "    g/=10\n",
    "    gammas.append(g)\n",
    "\n",
    "all_good4 = {}\n",
    "\n",
    "kernel = 'sigmoid'\n",
    "min_acc = 0.96\n",
    "weights = [1,5]\n",
    "\n",
    "for data in [m_t_s,m_t]:\n",
    "    all_good4[kernel] = good_SVM_classifiers(kernel, weights, cies, data, max_fpr, min_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No good results printing out after many hours?\n",
    "\n",
    "shouldn't have tried to have it unscaled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 - RandomizedSearchCV()\n",
    "\n",
    "enough of this manual labour - let's try the in-built method that I discovered too late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make parameters to try\n",
    "\n",
    "dc = 0.2\n",
    "staerd = dc\n",
    "cies = []\n",
    "for i in range(10):\n",
    "    cies.append(staerd)\n",
    "    if i % 9 == 0 and i >0:\n",
    "        dc*=10\n",
    "    staerd = staerd+dc\n",
    "\n",
    "g = 1\n",
    "gammas =['auto']\n",
    "for i in range(10):        \n",
    "    g/=10\n",
    "    gammas.append(g)\n",
    " \n",
    "weights = [1,3,5,7,9,10,15,20,25,30,40,60,80,100]\n",
    "\n",
    "# Make grid of parameters to check:\n",
    "svm_grid = {'C': cies, 'class_weight': [{1:1, -1:x} for x in weights], 'gamma': gammas}\n",
    "svm_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_random = RandomizedSearchCV(estimator = SVC(kernel = 'sigmoid', max_iter = 1000), param_distributions=svm_grid, \n",
    "                                scoring = scorer, n_iter = 500, cv = 5, random_state = 42, n_jobs = -1)\n",
    "svm_random.fit(big_train_X, big_train_y)\n",
    "show_best(svm_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turns out it only found garbage??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision / Recall curve for classifiers found in CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions = [1, 1,1,1,1,1]\n",
    "recalls = [0.99, 0.97, 0.99, 0.98, .97,0.93]\n",
    "\n",
    "plt.plot(precisions, recalls, 'bo')\n",
    "plt.title(\"Precision/Recall for SVMs\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contents:\n",
    "    - Helper functions \n",
    "    - Experiment 1 \n",
    "    - Experiment 2 \n",
    "    - Experiment 3 \n",
    "    - Experiment 4 \n",
    "    - Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def big_random_search(scorer, n_iterations, weights, max_depth=list(range(5,100,5)), n_estimators=list(range(5,200,5)), min_samples_split=[2,5,10], max_features=['sqrt', 'log2',100, 1000, 10000, 30000]):\n",
    "    \"\"\"\n",
    "    Use: \n",
    "        ensemble = big_random_search(scorer, n_iterations, weights, max_depth, n_estimators, min_samples_split, max_features):\n",
    "    Before: \n",
    "        scorer is a scorer from sklearn.metrics, made from a scoring/loss function\n",
    "            or a string which is valid as argument 'scoring' to RandomizedSearchCV\n",
    "        n_iterations controls how long the random search is \n",
    "        rest of arguments are parameters for the random forest \n",
    "    After: \n",
    "        ensemble is a random forest found through RandomizedSearchCV given the parameters \n",
    "    \"\"\"\n",
    "    bootstrap  = [True, False]\n",
    "    class_weights = [{1:1,-1:x} for x in weights]\n",
    "    min_samples_leaf = [1,2,5,10]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': \n",
    "                   max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, \n",
    "                   'bootstrap': bootstrap, 'class_weight': class_weights}\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, \n",
    "                                   scoring = scorer, n_iter = n_iterations, cv = 5, random_state = 42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(big_train_X, big_train_y)\n",
    "    \n",
    "    return rf_random\n",
    "\n",
    "def my_score_function(y_true, y_predict):\n",
    "    \"\"\"\n",
    "    Use: \n",
    "        score = my_score_function(y_true,y_predict)\n",
    "    Before:\n",
    "        y_true are true labels, y_predict predicted labels \n",
    "    After: \n",
    "        score is an evaluation of how good the prediction was\n",
    "        (only good if the fpr was adequate and recall is good)\n",
    "    \"\"\"\n",
    "    con = confusion_matrix(y_true,y_predict)\n",
    "    precision, accuracy, fpr, recall = conf_interpretation(con)\n",
    "    if fpr <= 1/500:\n",
    "        score =5* recall\n",
    "    else:\n",
    "        score = 0\n",
    "        \n",
    "    return score \n",
    "\n",
    "scorer = metrics.make_scorer(my_score_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline:\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params()\n",
    "#print(train_avg_cv(clf,m_t,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "    - Find optimal precision \n",
    "    \n",
    "    - Display results \n",
    "\n",
    "    - Search further around the result for models that were good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(5,200,5))\n",
    "max_features = ['sqrt', 'log2',100, 1000, 10000, 30000]\n",
    "max_depth = list(range(5,100,5))\n",
    "min_samples_split = [2,5,10]\n",
    "weights = [0.1, 0.2, 0.5, 1,3,5,7,9,15,20]\n",
    "\n",
    "rf_precision = big_random_search('precision', 20, weights, max_depth, n_estimators, min_samples_split, max_features)\n",
    "\n",
    "show_best(rf_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good parameters found: \n",
    "    weight = 5\n",
    "    max_depth = 65 \n",
    "    n_estimators = 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further search for high recall around the one found \n",
    "\n",
    "rf_no_fn_hi_recall = big_random_search(metrics.make_scorer(my_score_function), 50, [3,5,7,9], [55,60,65,70], [20,25,30])\n",
    "\n",
    "show_best(rf_no_fn_hi_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "    - Find optimal recall \n",
    "    \n",
    "    - Display results \n",
    "\n",
    "    - Search further around the result for models that were good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1, 0.2, 0.5, 1,3,5,7,9,15,20]\n",
    "rf_recall = big_random_search(scorer, 20, weights)\n",
    "show_best(rf_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "    - Find optimal accuracy \n",
    "    \n",
    "    - Display results \n",
    "\n",
    "    - a) Search further around the result for models that were good.\n",
    "    \n",
    "    - b) Adjust the probability threshold needed to classify as spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1, 0.2, 0.5, 1,3,5,7,9,15,20]\n",
    "rf_roc_auc = big_random_search('roc_auc', 20, weights)\n",
    "show_best(rf_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 a)  Search around the high accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high accuracy parameters:\n",
    "weight = 1\n",
    "max_depth = 80\n",
    "max_features = 1000 \n",
    "min_samples_leaf = 2 \n",
    "min_samples_split = 2 \n",
    "n_estimators = 45 \n",
    "\n",
    "\n",
    "rf_hi_acc = big_random_search(scorer, 80, [0.5,1,2,5], [70,75,80,85,90], [40,45,50,55,60], [2,3], [800,1000, 1200])\n",
    "show_best(rf_hi_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 b) Find the probability threshold needed to classify as spam without false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rf_hi_acc.best_estimator_\n",
    "predicted_spam_p = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "def adjusted_classes(spam_probabilities,t):\n",
    "    return [1 if y >= t else 0 for y in spam_probabilities]\n",
    "\n",
    "threshold = 0.5\n",
    "for i in range(50):\n",
    "    print(threshold + i/100)\n",
    "    print(confusion_matrix(y_test, adjusted_classes(predicted_spam_p, threshold + i/100)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raising the threshold of probability decreases FP at the cost of some FN. \n",
    "raising it to 52% for the classifier found removes the single FP from the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4       -   search randomly over a big grid and see if something pops up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_custom_score_big_search = big_random_search(scorer, 300, [0.1, 0.2, 0.5, 1,3,5,7,9,15,20,30])\n",
    "show_best(rf_custom_score_big_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5  -  do exhaustive search over relatively big grid \n",
    "\n",
    "Try combinations of the parameters whose models were fairly good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the custom scorer\n",
    "\n",
    "class_weight = (1,3,5, 7, 15)\n",
    "max_depth = (50,55, 60, 65, 70, 75,85)\n",
    "min_samples_split = (2,5,10)   \n",
    "max_features = (100, 1000,'sqrt')\n",
    "min_samples_leaf = (1,5)\n",
    "n_estimators = (20,40, 80,120)  \n",
    "Bootstrap = False \n",
    "class_weights = [{1: x} for x in class_weight]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, \n",
    "               'bootstrap': bootstrap, 'class_weight': class_weights}\n",
    "\n",
    "rf_exhaustive = GridSearchCV(estimator = RandomForestClassifier(), param_grid = random_grid, scoring=scorer,cv = 5,  n_jobs = -1)\n",
    "rf_exhaustive.fit(big_train_X, big_train_y)\n",
    "show_best(rf_exhaustive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the default scorer\n",
    "\n",
    "class_weight = (1,3,5, 7, 15)\n",
    "max_depth = (50,55, 60, 65, 70, 75,85)\n",
    "min_samples_split = (2,5,10)   \n",
    "max_features = (100, 1000,'sqrt')\n",
    "min_samples_leaf = (1,5)\n",
    "n_estimators = (20,40, 80,120)  \n",
    "Bootstrap = False \n",
    "class_weights = [{1: x} for x in class_weight]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, \n",
    "               'bootstrap': bootstrap, 'class_weight': class_weights}\n",
    "\n",
    "rf_exhaustive2 = GridSearchCV(estimator = RandomForestClassifier(), param_grid = random_grid, scoring=None,cv = 5,  n_jobs = -1)\n",
    "rf_exhaustive2.fit(big_train_X, big_train_y)\n",
    "show_best(rf_exhaustive2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6 \n",
    "\n",
    "Try out training with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Make a training set with 80% of the data, tfidf \n",
    "import scipy.sparse as sp\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = cvkfold(tfidf_m_t,l,5)\n",
    "\n",
    "big_train_X = sp.csr_matrix(np.concatenate((X_validate[0].toarray(),X_train[0].toarray()),axis=0))\n",
    "big_train_y = np.concatenate((y_validate[0],y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_random_search(scorer, n_iterations, weights, max_depth=list(range(5,100,5)), n_estimators=list(range(5,200,5)), min_samples_split=[2,5,10], max_features=['sqrt', 'log2',100, 1000, 10000, 30000]):\n",
    "    \"\"\"\n",
    "    Use: \n",
    "        ensemble = big_random_search(scorer, n_iterations, weights, max_depth, n_estimators, min_samples_split, max_features):\n",
    "    Before: \n",
    "        scorer is a scorer from sklearn.metrics, made from a scoring/loss function\n",
    "            or a string which is valid as argument 'scoring' to RandomizedSearchCV\n",
    "        n_iterations controls how long the random search is \n",
    "        rest of arguments are parameters for the random forest \n",
    "    After: \n",
    "        ensemble is a random forest found through RandomizedSearchCV given the parameters \n",
    "    \"\"\"\n",
    "    bootstrap  = [True, False]\n",
    "    class_weights = [{1:1,-1:x} for x in weights]\n",
    "    min_samples_leaf = [1,2,5,10]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': \n",
    "                   max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, \n",
    "                   'bootstrap': bootstrap, 'class_weight': class_weights}\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, \n",
    "                                   scoring = scorer, n_iter = n_iterations, cv = 5, random_state = 42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(big_train_X, big_train_y)\n",
    "    \n",
    "    return rf_random\n",
    "\n",
    "n_estimators = list(range(5,200,5))\n",
    "max_features = ['sqrt', 'log2',100, 1000, 10000, 30000]\n",
    "max_depth = list(range(5,100,5))\n",
    "min_samples_split = [2,5,10]\n",
    "weights = [0.1, 0.2, 0.5, 1,3,5,7,9,15,20]\n",
    "\n",
    "rf_custom_idf = big_random_search(scorer, 300, weights, max_depth, n_estimators, min_samples_split, max_features)\n",
    "\n",
    "show_best(rf_custom_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall for good classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions = [0.985, 1,  1,  0.934,             1,  0.983 ,                1 - 1/1567,  1 - 5/1607]\n",
    "recalls = [0.999, 1-410/1606, 1 - 249/1606, 1,   1 - 57/1606, 1 - 2/1604, 1 - 40/1606,   1 - 4/1602 ]\n",
    "\n",
    "plt.plot(precisions, recalls, 'bo')\n",
    "plt.title(\"Precision/Recall for Random Forests\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC fyrir RF \n",
    "model = RandomForestClassifier(bootstrap=False, class_weight={1: 1, -1: 1},\n",
    "            criterion='gini', max_depth=85, max_features=1000,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=145, n_jobs=None, oob_score=False,\n",
    "            random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "model.fit(big_train_X, big_train_y)\n",
    "\n",
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ =roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example') \n",
    "plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
